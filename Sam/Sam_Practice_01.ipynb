{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_docs import modeling\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pathlib\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# solution #1\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   try:\n",
    "#     # Currently, memory growth needs to be the same across GPUs\n",
    "#     for gpu in gpus:\n",
    "#       tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#     logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#   except RuntimeError as e:\n",
    "#     # Memory growth must be set before GPUs have been initialized\n",
    "#     print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "memorysize = 6500\n",
    "# solution #2\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memorysize)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version:  2.1.0\n",
      "Number of GPU available:  2\n"
     ]
    }
   ],
   "source": [
    "tfds.disable_progress_bar()  # disable tqdm progress bar\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "print(\"TensorFlow Version: \", tf.__version__)\n",
    "print(\"Number of GPU available: \", len(tf.config.experimental.list_physical_devices(\"GPU\")))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 100\n",
    "IMG_WIDTH = 100\n",
    "BATCH_SIZE = 64\n",
    "val_fraction = 30\n",
    "max_epochs= 300"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# parameters to change\n",
    "augment_degree = 0.10\n",
    "samplesize = [1200, 1600] #old, young\n",
    "shuffle_buffer_size = 1000000  # take first 100 from dataset and shuffle and pick one."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def read_and_label(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "    img = occlude(img, file_path)\n",
    "    return img, label\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return tf.reshape(tf.where(parts[-4] == CLASS_NAMES), [])\n",
    "\n",
    "def occlude(image, file_path):\n",
    "    maskpth = tf.strings.regex_replace(file_path, 'image', 'label')\n",
    "    mask = tf.io.read_file(maskpth)\n",
    "    mask = tf.image.decode_jpeg(mask, channels=1)\n",
    "    mask = tf.image.convert_image_dtype(mask, tf.float16)\n",
    "    mask = tf.image.resize(mask, [IMG_WIDTH, IMG_HEIGHT])\n",
    "    mask = tf.math.greater(mask, 0.25)\n",
    "    # comment below line to show cell only\n",
    "    # mask = tf.math.logical_not(mask)\n",
    "    maskedimg = tf.where(mask, image, tf.ones(tf.shape(image)))\n",
    "    return maskedimg\n",
    "\n",
    "def augment(image, label):\n",
    "    degree = augment_degree\n",
    "    if degree == 0:\n",
    "        return image, label\n",
    "    image = tf.image.random_hue(image, max_delta=degree, seed=5)\n",
    "    image = tf.image.random_contrast(image, 1-degree, 1+degree, seed=5)  # tissue quality\n",
    "    image = tf.image.random_saturation(image, 1-degree, 1+degree, seed=5)  # stain quality\n",
    "    image = tf.image.random_brightness(image, max_delta=degree)  # tissue thickness, glass transparency (clean)\n",
    "    image = tf.image.random_flip_left_right(image, seed=5)  # cell orientation\n",
    "    image = tf.image.random_flip_up_down(image, seed=5)  # cell orientation\n",
    "    return image, label\n",
    "\n",
    "def balance(data_dir):\n",
    "    tmp = [0]\n",
    "    for CLASS, n in zip(CLASS_NAMES, samplesize):\n",
    "        secs = [_ for _ in data_dir.glob(CLASS+'/*')]\n",
    "        for idx,sec in enumerate(secs):\n",
    "            sec = os.path.join(sec, 'image/*.jpg')\n",
    "            list_ds = tf.data.Dataset.list_files(sec)\n",
    "            # subsample\n",
    "            list_ds = (list_ds\n",
    "                       .shuffle(shuffle_buffer_size)\n",
    "                       .take(n)\n",
    "                       )\n",
    "            labeled_ds_org = list_ds.map(read_and_label, num_parallel_calls=AUTOTUNE)\n",
    "            labeled_ds = labeled_ds_org.map(augment,num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "            # add augment\n",
    "            sampleN = len(list(labeled_ds))\n",
    "            while sampleN < n:\n",
    "                labeled_ds_aug = (labeled_ds_org\n",
    "                                  .shuffle(shuffle_buffer_size)\n",
    "                                  .take(n-sampleN)\n",
    "                                  .map(augment,num_parallel_calls=AUTOTUNE)\n",
    "                                  )\n",
    "                labeled_ds = labeled_ds.concatenate(labeled_ds_aug)\n",
    "                sampleN = len(list(labeled_ds))\n",
    "            print('list_ds: ', len(list(labeled_ds)),CLASS)\n",
    "            # append\n",
    "            if tmp[0] == 0:\n",
    "                tmp[idx] = labeled_ds\n",
    "            else:\n",
    "                labeled_ds = tmp[0].concatenate(labeled_ds)\n",
    "                tmp[0] = labeled_ds\n",
    "        print(CLASS, ': sample size =', len(list(tmp[0])))\n",
    "    return tmp[0].shuffle(shuffle_buffer_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# list location of all training images\n",
    "train_data_dir = '/home/kuki2070s2/Desktop/Synology/aging/data/cnn_dataset/train'\n",
    "train_data_dir = pathlib.Path(train_data_dir)\n",
    "CLASS_NAMES = np.array([item.name for item in train_data_dir.glob('*') if item.name != \".DS_store\"])\n",
    "CLASS_NAMES = sorted(CLASS_NAMES, key=str.lower) #sort alphabetically case-insensitive"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'shuffle'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-14-05c6bf9f818a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrain_labeled_ds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbalance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_data_dir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mtrain_image_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_labeled_ds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'training set size : '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_image_count\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mval_image_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_image_count\u001B[0m \u001B[0;34m//\u001B[0m \u001B[0;36m100\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mval_fraction\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'validation size: '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_image_count\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-9-932e91b96af6>\u001B[0m in \u001B[0;36mbalance\u001B[0;34m(data_dir)\u001B[0m\n\u001B[1;32m     69\u001B[0m                 \u001B[0mtmp\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlabeled_ds\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mCLASS\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m': sample size ='\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtmp\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 71\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtmp\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshuffle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshuffle_buffer_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     72\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'int' object has no attribute 'shuffle'"
     ]
    }
   ],
   "source": [
    "train_labeled_ds = balance(train_data_dir)\n",
    "train_image_count = len(list(train_labeled_ds))\n",
    "print('training set size : ', train_image_count)\n",
    "val_image_count = train_image_count // 100 * val_fraction\n",
    "print('validation size: ', val_image_count)\n",
    "train_image_count2 = train_image_count-val_image_count\n",
    "print('training set size after split : ', train_image_count2)\n",
    "STEPS_PER_EPOCH = train_image_count2 // BATCH_SIZE\n",
    "VALIDATION_STEPS = val_image_count // BATCH_SIZE\n",
    "print('train step #',STEPS_PER_EPOCH)\n",
    "print('validation step #',VALIDATION_STEPS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_labeled_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-12-bef284ae9feb>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfigure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfigsize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0melem\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_labeled_ds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtake\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m     \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0melem\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0mlabel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0melem\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0max\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msubplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_labeled_ds' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for idx, elem in enumerate(train_labeled_ds.take(100)):\n",
    "    img = elem[0]\n",
    "    label = elem[1]\n",
    "    ax = plt.subplot(10,10,idx+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(CLASS_NAMES[label].title())\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "target= 'sample_data'\n",
    "if not os.path.exists(target): os.mkdir(target)\n",
    "plt.savefig(target + '/aug10_all_training data.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}